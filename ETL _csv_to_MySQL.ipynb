{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d66e5947-18b2-419b-8a5e-bf2a07700d38",
   "metadata": {},
   "source": [
    "### ETL for Loading Downloaded Dataset to MySQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "befd7516-5ae9-48fc-9087-d901370ab64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading csv files from my folders into pandas dataframe\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Specific folder address\n",
    "folder_address = r\"C:\\Users\\alank\\Documents\\Data Analyst Projects\\Azure End to End Data Anlaytics Project\\olist dataset\"\n",
    "\n",
    "# List all CSV files in the specified folder\n",
    "csv_files = [os.path.join(folder_address, file) for file in os.listdir(folder_address) if file.endswith(\".csv\")]\n",
    "\n",
    "# Read each CSV file into a DataFrame\n",
    "dataframes = []\n",
    "for filename in csv_files:\n",
    "    dataframe = pd.read_csv(filename)\n",
    "    dataframes.append(dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7efffba9-7ff0-4442-8325-a226a95b4ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['olist_customers_dataset.csv',\n",
       " 'olist_geolocation_dataset.csv',\n",
       " 'olist_orders_dataset.csv',\n",
       " 'olist_order_items_dataset.csv',\n",
       " 'olist_order_payments_dataset.csv',\n",
       " 'olist_order_reviews_dataset.csv',\n",
       " 'olist_products_dataset.csv',\n",
       " 'olist_sellers_dataset.csv',\n",
       " 'product_category_name_translation.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting the csv file names into a list\n",
    "csv_filenames = [os.path.basename(filename) for filename in csv_files]\n",
    "csv_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0001fc6d-e02f-450c-8532-a409cbeeea53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymysql\n",
      "  Downloading PyMySQL-1.1.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Downloading PyMySQL-1.1.0-py3-none-any.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/44.8 kB ? eta -:--:--\n",
      "   ------------------------------------ --- 41.0/44.8 kB 960.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.8/44.8 kB 1.1 MB/s eta 0:00:00\n",
      "Installing collected packages: pymysql\n",
      "Successfully installed pymysql-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0465b95c-5e0a-42a1-b697-d4f6ce68072b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7386a64b-73ff-4f27-9f37-ec2c7720ff73",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pymysql.connect(host=\"localhost\", user=\"root\", password=\"password\", database=\"olist_db\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "444dabc8-a62c-41d5-899c-0bad6ddb376e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE `olist_customers_dataset` (`customer_id` VARCHAR(255) NOT NULL,`customer_unique_id` VARCHAR(255) NOT NULL,`customer_zip_code_prefix` INT NOT NULL,`customer_city` VARCHAR(255) NOT NULL,`customer_state` VARCHAR(255) NOT NULL)\n",
      "CREATE TABLE `olist_geolocation_dataset` (`geolocation_zip_code_prefix` INT NOT NULL,`geolocation_lat` INT NOT NULL,`geolocation_lng` INT NOT NULL,`geolocation_city` VARCHAR(255) NOT NULL,`geolocation_state` VARCHAR(255) NOT NULL)\n",
      "CREATE TABLE `olist_orders_dataset` (`order_id` VARCHAR(255) NOT NULL,`customer_id` VARCHAR(255) NOT NULL,`order_status` VARCHAR(255) NOT NULL,`order_purchase_timestamp` VARCHAR(255) NOT NULL,`order_approved_at` VARCHAR(255) NOT NULL,`order_delivered_carrier_date` VARCHAR(255) NOT NULL,`order_delivered_customer_date` VARCHAR(255) NOT NULL,`order_estimated_delivery_date` VARCHAR(255) NOT NULL)\n",
      "CREATE TABLE `olist_order_items_dataset` (`order_id` VARCHAR(255) NOT NULL,`order_item_id` INT NOT NULL,`product_id` VARCHAR(255) NOT NULL,`seller_id` VARCHAR(255) NOT NULL,`shipping_limit_date` VARCHAR(255) NOT NULL,`price` INT NOT NULL,`freight_value` INT NOT NULL)\n",
      "CREATE TABLE `olist_order_payments_dataset` (`order_id` VARCHAR(255) NOT NULL,`payment_sequential` INT NOT NULL,`payment_type` VARCHAR(255) NOT NULL,`payment_installments` INT NOT NULL,`payment_value` INT NOT NULL)\n",
      "CREATE TABLE `olist_order_reviews_dataset` (`review_id` VARCHAR(255) NOT NULL,`order_id` VARCHAR(255) NOT NULL,`review_score` INT NOT NULL,`review_comment_title` VARCHAR(255) NOT NULL,`review_comment_message` VARCHAR(255) NOT NULL,`review_creation_date` VARCHAR(255) NOT NULL,`review_answer_timestamp` VARCHAR(255) NOT NULL)\n",
      "CREATE TABLE `olist_products_dataset` (`product_id` VARCHAR(255) NOT NULL,`product_category_name` VARCHAR(255) NOT NULL,`product_name_lenght` INT NOT NULL,`product_description_lenght` INT NOT NULL,`product_photos_qty` INT NOT NULL,`product_weight_g` INT NOT NULL,`product_length_cm` INT NOT NULL,`product_height_cm` INT NOT NULL,`product_width_cm` INT NOT NULL)\n",
      "CREATE TABLE `olist_sellers_dataset` (`seller_id` VARCHAR(255) NOT NULL,`seller_zip_code_prefix` INT NOT NULL,`seller_city` VARCHAR(255) NOT NULL,`seller_state` VARCHAR(255) NOT NULL)\n",
      "CREATE TABLE `product_category_name_translation` (`product_category_name` VARCHAR(255) NOT NULL,`product_category_name_english` VARCHAR(255) NOT NULL)\n"
     ]
    }
   ],
   "source": [
    "# Create tables for each CSV file\n",
    "\n",
    "for filename in csv_filenames:\n",
    "    # Extract table name from filename\n",
    "    table_name = filename.split(\".\")[0]\n",
    "\n",
    "    # Read CSV data into a DataFrame\n",
    "    dataframe = pd.read_csv(filename)\n",
    "\n",
    "    # Prepare SQL query to create the table\n",
    "    sql_query = \"CREATE TABLE `\" + table_name + \"` (\"\n",
    "\n",
    "    # Construct column definitions based on DataFrame column names and data types\n",
    "    column_definitions = []\n",
    "    for column_name, data_type in zip(dataframe.columns, dataframe.dtypes):\n",
    "        if pd.api.types.is_string_dtype(data_type):\n",
    "            column_definition = \"`\" + column_name + \"` VARCHAR(255) NOT NULL\"\n",
    "        elif pd.api.types.is_numeric_dtype(data_type):\n",
    "            column_definition = \"`\" + column_name + \"` INT NOT NULL\"\n",
    "        elif pd.api.types.is_datetime_dtype(data_type):\n",
    "            column_definition = \"`\" + column_name + \"` DATETIME NOT NULL\"\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported data type for column:\", column_name)\n",
    "\n",
    "        column_definitions.append(column_definition)\n",
    "\n",
    "    # Add primary key constraint if necessary\n",
    "    if \"id\" in dataframe.columns:\n",
    "        sql_query += \"PRIMARY KEY (`id`),\"\n",
    "\n",
    "    # Add remaining column definitions\n",
    "    sql_query += \",\".join(column_definitions) + \")\";\n",
    "    print(sql_query)\n",
    "\n",
    "    # Execute SQL query to create the table\n",
    "    cursor = db.cursor()\n",
    "    cursor.execute(sql_query)\n",
    "\n",
    "    # Close the cursor\n",
    "    cursor.close()\n",
    "\n",
    "# Close MySQL connection\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82cf2dcb-1dfd-46dc-9c12-b92bc9c581d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_names=[]\n",
    "for filename in csv_filenames:\n",
    "    # Extract table name from filename\n",
    "    table_name = filename.split(\".\")[0]\n",
    "    table_names.append(table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ab9cd68-52b5-4bd5-9abd-b529e667ff88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['olist_customers_dataset',\n",
       " 'olist_geolocation_dataset',\n",
       " 'olist_orders_dataset',\n",
       " 'olist_order_items_dataset',\n",
       " 'olist_order_payments_dataset',\n",
       " 'olist_order_reviews_dataset',\n",
       " 'olist_products_dataset',\n",
       " 'olist_sellers_dataset',\n",
       " 'product_category_name_translation']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0fee7811-c514-4954-ab54-61d77e106121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "olist_customers_dataset loaded\n",
      "olist_geolocation_dataset loaded\n",
      "olist_orders_dataset loaded\n",
      "olist_order_items_dataset loaded\n",
      "olist_order_payments_dataset loaded\n",
      "olist_order_reviews_dataset loaded\n",
      "olist_products_dataset loaded\n",
      "olist_sellers_dataset loaded\n",
      "product_category_name_translation loaded\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from urllib.parse import quote\n",
    "\n",
    "# Replace 'your_username', 'your_password', 'your_database', and 'localhost' with your actual MySQL credentials\n",
    "username = 'root'\n",
    "password = 'password'\n",
    "host = 'localhost'\n",
    "database = 'olist_db'\n",
    "\n",
    "# Encode the password\n",
    "encoded_password = quote(password)\n",
    "\n",
    "# Create the connection string\n",
    "connection_string = f\"mysql+pymysql://{username}:{encoded_password}@{host}/{database}\"\n",
    "\n",
    "# Create the engine\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Loop to save each DataFrame to its corresponding table\n",
    "for dataframe, table_name in zip(dataframes, table_names):\n",
    "    dataframe.to_sql(table_name, con=engine, if_exists='replace', index=False)\n",
    "    print(table_name + \" loaded\")\n",
    "\n",
    "# Dispose of the engine\n",
    "engine.dispose()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce37267f-1a38-46fe-af9f-281cf0f30c01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
